{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Description "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/walkerkq/musiclyrics\n",
    "\n",
    "Billboard has published a Year-End Hot 100 every December since 1958. The chart measures the performance of singles in the U.S. throughout the year. Using R, I’ve combined the lyrics from 50 years of Billboard Year-End Hot 100 (1965-2015) into one dataset for analysis. You can download that dataset here.\n",
    "\n",
    "The songs used for analysis were scraped from Wikipedia’s entry for each Billboard Year-End Hot 100 Songs (e.g., 2014). This is the year-end chart, not weekly rankings. Many artists have made the weekly chart but not the final year end chart. The final chart is calculated using an inverse point system based on the weekly Billboard charts (100 points for a week at number one, 1 point for a week at number 100, etc).\n",
    "\n",
    "I used the xml and RCurl packages to scrape song and artist names from each Wikipedia entry. I then used that list to scrape lyrics from sites that had predictable URL strings (for example, metrolyrics.com uses metrolyrics.com/SONG-NAME-lyrics-ARTIST-NAME.html). If the first site scrape failed, I moved onto the second, and so on. About 78.9% of the lyrics were scraped from metrolyics.com, 15.7% from songlyrics.com, 1.8% from lyricsmode.com. About 3.6% (187/5100) were unavailable.\n",
    "\n",
    "The dataset features 5100 observations with the features rank (1-100), song, artist, year, lyrics, and source. The artist feature is fairly standardized thanks to Wikipedia, but there is still quite a bit of noise when it comes to artist collaborations (Justin Timberlake featuring Timbaland, for example). If there were any errors in the lyrics that were scraped, such as spelling errors or derivatives like \"nite\" instead of \"night,\" they haven't been corrected.\n",
    "\n",
    "Full analysis can be found here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "from Levenshtein import distance as levenshtein_distance\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lyrics Top-100 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file_incomplete = \"datasets/billboard_lyrics_1964-2015.csv\"\n",
    "data_file = \"datasets/billboard_full.csv\"\n",
    "\n",
    "df_incomplete = pd.read_csv(data_file_incomplete, encoding = \"ANSI\") # utf-8 encoding doesn't work somehow :(\n",
    "df = pd.read_csv(data_file, index_col=0, header=0, sep=\",\") \n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.Artist.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of years in Top 100 per Song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count = df.groupby([\"Artist\", \"Song\"]).Year.agg(list).to_frame()\n",
    "df_count[\"Count\"] = df_count.Year.apply(len)\n",
    "df_count = df_count.sort_values(\"Count\", ascending = False)\n",
    "df_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pie(df_count[\"Count\"].value_counts(), labels = [1, 2], autopct='%1.1f%%')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vc_genre = df.Genre.value_counts()\n",
    "vc_genre = vc_genre[vc_genre > 70] # Filter very unfrequent\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.pie(vc_genre.values, labels = vc_genre.index, autopct='%1.1f%%')\n",
    "# plt.savefig(\"images/genre_distribution.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of songs in top 100 per artist (if a song is twice, is counted twice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.Artist.value_counts().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_songCounts = df.groupby(\"Artist\").Song.count()\n",
    "df_rndArtist = df_songCounts.to_frame().reset_index().groupby(\"Song\").agg(list)\n",
    "df_rndArtist[\"Artist\"] = df_rndArtist[\"Artist\"].apply(lambda a : np.random.choice(a, 1)[0])\n",
    "\n",
    "df_labels = pd.DataFrame(range(1, df_songCounts.max() + 1), columns = [\"Song\"])\n",
    "df_labels[\"Artist\"] = \"\"\n",
    "df_labels = df_labels.set_index(\"Song\")\n",
    "df_labels.update(df_rndArtist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = df_songCounts.value_counts()\n",
    "tmp[tmp.index <= 3].sum() / tmp.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bins = range(1, df_songCounts.max() + 1)\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.hist(df_songCounts, bins = bins)\n",
    "plt.xticks(bins, df_labels[\"Artist\"], rotation='vertical')\n",
    "plt.yscale(\"log\")\n",
    "plt.title(\"Number of times appearing in Top-100 per Artist, with randomly selected artist per bin\")\n",
    "# plt.savefig(\"images/songs_per_artist.png\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lyrics statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lyrics_lengths = df.Lyrics.apply(lambda s : len(s.split(\" \")))\n",
    "\n",
    "bins = range(1, 1000)\n",
    "plt.hist(lyrics_lengths, bins = bins)\n",
    "plt.title(\"Number of words per song\")\n",
    "plt.savefig(\"words.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics_lengths.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics_lengths_unique = df.Lyrics.apply(lambda s : len(set(s.split(\" \"))))\n",
    "\n",
    "bins = range(1, 1000)\n",
    "plt.hist(lyrics_lengths_unique, bins = bins)\n",
    "plt.title(\"Number of unique words per song\")\n",
    "plt.savefig(\"unique_words.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lyrics_lengths_unique.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clusterisation of texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pos_tag, sent_tokenize, wordpunct_tokenize\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "def lemmatize(token, pos_tag):\n",
    "    tag = {\n",
    "        'N': wn.NOUN,\n",
    "        'V': wn.VERB,\n",
    "        'R': wn.ADV,\n",
    "        'J': wn.ADJ\n",
    "    }.get(pos_tag[0], wn.NOUN)\n",
    "    return lemmatizer.lemmatize(token, tag)\n",
    "\n",
    "def preprocess_lyrics(lyrics):\n",
    "    tagged_tokens = pos_tag(wordpunct_tokenize(lyrics))\n",
    "    preprocessed = [lemmatize(token, tag) for (token, tag) in tagged_tokens if not token in stop_words]\n",
    "    return \" \".join(preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_lyrics = df.Lyrics.fillna(\"\").apply(preprocess_lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise the count vectorizer with the English stop words\n",
    "count_vectorizer = CountVectorizer(stop_words='english', preprocessor = None)\n",
    "# Fit and transform the processed titles\n",
    "count_data = count_vectorizer.fit_transform(preprocessed_lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_topics(model, count_vectorizer, n_top_words):\n",
    "    words = count_vectorizer.get_feature_names()\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"\\nTopic #%d:\" % topic_idx)\n",
    "        print(\" \".join([words[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "        \n",
    "# Tweak the two parameters below\n",
    "number_topics = 5\n",
    "number_words = 4\n",
    "# Create and fit the LDA model\n",
    "lda = LDA(n_components=number_topics, n_jobs=-1)\n",
    "lda.fit(count_data)\n",
    "# Print the topics found by the LDA model\n",
    "print(\"Topics found via LDA:\")\n",
    "print_topics(lda, count_vectorizer, number_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors_10 = lda.transform(count_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(vectors_10[:100, 0], vectors_10[:100, 1], color = \"red\")\n",
    "plt.scatter(vectors_10[5000:, 0], vectors_10[5000:, 1], color = \"blue\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "svd = TruncatedSVD(2)\n",
    "vectors_2 = svd.fit_transform(vectors_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(vectors_2[:100, 0], vectors_2[:100, 1], color = \"red\")\n",
    "plt.scatter(vectors_2[5000:, 0], vectors_2[5000:, 1], color = \"blue\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "documents = [TaggedDocument(doc.split(\" \"), [i]) for i, doc in enumerate(df.Lyrics.fillna(\"\"))]\n",
    "model = Doc2Vec(documents, vector_size=300, window=4, min_count=1, workers=4, epochs = 10, dbow_words = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"I cant get no satisfaction\"\n",
    "vector = model.infer_vector(sentence.split(\" \"))\n",
    "documents[model.docvecs.most_similar([vector])[1][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents[4480]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "svd = TruncatedSVD(2)\n",
    "vectors_2 = svd.fit_transform(model.docvecs.vectors_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(vectors_2[:100, 0], vectors_2[:100, 1], color = \"red\")\n",
    "plt.scatter(vectors_2[5000:, 0], vectors_2[5000:, 1], color = \"blue\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SimonRoquette\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b956c01a16d4830a768f087d549304f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SimonRoquette\\Anaconda3\\lib\\site-packages\\tqdm\\std.py:658: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "tqdm_notebook().pandas()\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entity_extractor(cols, song = False):\n",
    "    \"\"\"\n",
    "    Parametrable extraction\n",
    "    \"\"\"\n",
    "    ignore_entities = [\"CARDINAL\", \"MONEY\", \"ORDINAL\", \"QUANTITY\", \"TIME\"]\n",
    "    def extract_entities(row):\n",
    "        \"\"\"\n",
    "        Actual extraction\n",
    "        \"\"\"\n",
    "        entities = []\n",
    "        for col in cols:\n",
    "            if type(row[col]) == str:\n",
    "                entities += [(ent.text, ent.label_) for ent in nlp(row[col]).ents if ent.label_ not in ignore_entities]\n",
    "                \n",
    "        if song : \n",
    "            entities.append((row[\"Artist\"], \"PERSON\"))\n",
    "            entities.append((row[\"Song\"], \"WORK_OF_ART\"))\n",
    "            entities.append((row[\"Album\"], \"WORK_OF_ART\"))\n",
    "        \n",
    "        return entities\n",
    "    \n",
    "    return extract_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2aeca22a2eb64d8b89ea7271cafb1a26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1115.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "extraction_cols = [\"Content\", \"Summary\"]\n",
    "df_events[\"Entities_2\"] = df_events.progress_apply(entity_extractor(extraction_cols), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.757847533632287"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_events.Entities.apply(len).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41.422421524663676"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_events.Entities_2.apply(len).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.35599843688941"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Entities.apply(len).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "feb58435ac0449d79958e1ee6431fa3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5118.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df[\"Entities\"] = df.progress_apply(entity_extractor([\"Lyrics\"]), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.word_count.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"word_count\"] = df.Lyrics.apply(lambda x : len(x.split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 4), (5, 9), (10, 14), (15, 19)]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(m.start(), m.end()) for m in re.finditer('test', 'test test test test')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def getStartEnd_entities(row, events = False):\n",
    "    occurences = []\n",
    "    col = \"Summary\" if events else \"Lyrics_print\"\n",
    "    for ent, ent_type in set(row.Entities):\n",
    "        try:\n",
    "            occurences += [(ent, ent_type, m.start(), m.end()) for m in re.finditer(ent, row[col])]\n",
    "        except:\n",
    "            ent = re.sub('([\\[\\].,!?()\\*])', r'', ent)\n",
    "            occurences += [(ent, ent_type, m.start(), m.end())\n",
    "                           for m in re.finditer(ent, row[col])]\n",
    "    return sorted(occurences, key=lambda x : x[2])\n",
    "\n",
    "def choseEntity(row):\n",
    "    prev_end = 0\n",
    "    filteredEnts = []\n",
    "    for ent, ent_type, start, end in row[\"Entities_more\"]:\n",
    "        if prev_end > start:\n",
    "            # Entities are overlapping, forget this one\n",
    "            continue\n",
    "        filteredEnts.append((ent, ent_type, start, end))\n",
    "        prev_end = end\n",
    "    return filteredEnts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "791befc1d58e4a5183d2c3e73928a0ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5118.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af39684182bf4932acd72903e74fcaf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5118.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df[\"Entities_more\"] = df.progress_apply(getStartEnd_entities, axis = 1)\n",
    "df[\"Entities_more\"] = df.progress_apply(choseEntity, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f75ac8678bd41cb84445eb01b945312",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1115.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfd532eeccdf4b61801fa5dff11de8b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1115.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_events[\"Entities_more\"] = df_events.progress_apply(getStartEnd_entities, axis = 1)\n",
    "df_events[\"Entities_more\"] = df_events.progress_apply(choseEntity, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_refs(song_rows):\n",
    "    refs = []\n",
    "    for entity, label in song_rows.Entities:\n",
    "        entity = entity.lower()\n",
    "        for i, row in df_events.Entities.iteritems():\n",
    "            ents_lower = [ent.lower() for ent, lab in row]\n",
    "            if any([entity.lower() in low_ent or low_ent in entity for low_ent in ents_lower]):\n",
    "                refs.append(i)\n",
    "    return refs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb78ff1a85fe45fb81ee0ac1c0894472",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5118.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Add references to events in songs\n",
    "\"\"\"\n",
    "df[\"Refs\"] = df.progress_apply(find_refs, axis = 1)\n",
    "df[\"Refs\"] = df[\"Refs\"].apply(set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.filteredRefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SimonRoquette\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d5a38d289234949a97415e0bceb1d48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Add references to songs in events\n",
    "\"\"\"\n",
    "df_events[\"Refs\"] = [[] for i in range(len(df_events))]\n",
    "for i_song, refs in tqdm_notebook(df[\"Refs\"].iteritems()):\n",
    "    for i_event in refs:\n",
    "        df_events.iloc[i_event][\"Refs\"].append(i_song)\n",
    "        \n",
    "df_events[\"Refs\"] = df_events[\"Refs\"].apply(set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Refs\"].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.xs(4971).Lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = dict()\n",
    "for ents in df.Entities.apply(lambda x : [e[0] for e in x]).values:\n",
    "    for ent in ents :\n",
    "        if ent in s:\n",
    "            s[ent] +=1\n",
    "        else :\n",
    "            s[ent] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = {k: v for k, v in sorted(s.items(), key=lambda item: item[1], reverse=True)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "See the all the types of entities recognized\n",
    "\"\"\"\n",
    "\n",
    "ent_types = set()\n",
    "for s in df[\"Entities\"].apply(lambda x : set([e[1] for e in x])):\n",
    "    for ent in s:\n",
    "        ent_types.add(ent)\n",
    "ent_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(\"songs_with_refs.csv\")\n",
    "# df_events.to_csv(\"events_with_refs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"datasets/songs_with_refs.pickle\", \"wb\") as f :\n",
    "#     pickle.dump(df, f, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "# with open(\"datasets/events_with_refs.pickle\", \"wb\") as f :\n",
    "#     pickle.dump(df_events, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load refs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"datasets/songs_with_refs.pickle\", \"rb\") as f :\n",
    "    df = pickle.load(f)\n",
    "    \n",
    "with open(\"datasets/events_with_refs.pickle\", \"rb\") as f :\n",
    "    df_events = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Song</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Year</th>\n",
       "      <th>Lyrics</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Album</th>\n",
       "      <th>Refs</th>\n",
       "      <th>word_count</th>\n",
       "      <th>vect</th>\n",
       "      <th>sims</th>\n",
       "      <th>filteredRefs</th>\n",
       "      <th>Lyrics_print</th>\n",
       "      <th>Entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1044</th>\n",
       "      <td>41</td>\n",
       "      <td>Listen to what the man said</td>\n",
       "      <td>Wings</td>\n",
       "      <td>1975</td>\n",
       "      <td>All right ,  okay ,  he-he-he Very good to see...</td>\n",
       "      <td>Rock</td>\n",
       "      <td>Venus And Mars</td>\n",
       "      <td>{}</td>\n",
       "      <td>177</td>\n",
       "      <td>[0.09184183925390244, -0.9644627571105957, -0....</td>\n",
       "      <td>[0.919452421458788, 0.9557877725117744, 0.9023...</td>\n",
       "      <td>[]</td>\n",
       "      <td>All right, okay, he-he-he\\r\\nVery good to see ...</td>\n",
       "      <td>[(New Orleans, GPE), (blindWell, PERSON)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1104</th>\n",
       "      <td>1</td>\n",
       "      <td>Silly love songs</td>\n",
       "      <td>Wings</td>\n",
       "      <td>1976</td>\n",
       "      <td>You'd think that people would've had enough of...</td>\n",
       "      <td>Classic Rock</td>\n",
       "      <td>Wings At The Speed Of Sound</td>\n",
       "      <td>{}</td>\n",
       "      <td>356</td>\n",
       "      <td>[0.9979954957962036, -0.9818665981292725, -0.7...</td>\n",
       "      <td>[0.9473304240175289, 0.9037747111017586, 0.944...</td>\n",
       "      <td>[]</td>\n",
       "      <td>You'd think that people would've had enough of...</td>\n",
       "      <td>[(againI, PERSON), (againI, PERSON), (allHow, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1170</th>\n",
       "      <td>67</td>\n",
       "      <td>Let em in</td>\n",
       "      <td>Wings</td>\n",
       "      <td>1976</td>\n",
       "      <td>Someone knockin' at the door Somebody ringin' ...</td>\n",
       "      <td>Rock</td>\n",
       "      <td>Let Em In</td>\n",
       "      <td>{0, 512, 513, 5, 1033, 1034, 12, 525, 1041, 19...</td>\n",
       "      <td>161</td>\n",
       "      <td>[0.9771664142608643, -0.9817811250686646, -0.1...</td>\n",
       "      <td>[0.9666354500279337, 0.9205098334261539, 0.968...</td>\n",
       "      <td>[0, 513, 1034, 531, 1047, 543, 32, 38, 549, 10...</td>\n",
       "      <td>Someone knockin' at the door\\r\\nSomebody ringi...</td>\n",
       "      <td>[(Suzy, PERSON), (JohnMartin Luther, PERSON), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1321</th>\n",
       "      <td>18</td>\n",
       "      <td>With a little luck</td>\n",
       "      <td>Wings</td>\n",
       "      <td>1978</td>\n",
       "      <td>With a little luck we can help it out We can m...</td>\n",
       "      <td>Pop</td>\n",
       "      <td>All The Best</td>\n",
       "      <td>{}</td>\n",
       "      <td>390</td>\n",
       "      <td>[0.1736101657152176, -0.973969578742981, -0.24...</td>\n",
       "      <td>[0.9556965141341748, 0.9533317280316723, 0.961...</td>\n",
       "      <td>[]</td>\n",
       "      <td>With a little luck we can help it out\\r\\nWe ca...</td>\n",
       "      <td>[(end(There, PERSON), (end(There, PERSON), (lu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>52</td>\n",
       "      <td>Goodnight tonight</td>\n",
       "      <td>Wings</td>\n",
       "      <td>1979</td>\n",
       "      <td>Ooh Ooh Ooh ,  oooh  Don't get too tired for l...</td>\n",
       "      <td>Rock</td>\n",
       "      <td>Goodnight Tonight</td>\n",
       "      <td>{}</td>\n",
       "      <td>157</td>\n",
       "      <td>[0.8664616346359253, -0.9701489210128784, -0.5...</td>\n",
       "      <td>[0.8957604971886108, 0.9092488375300588, 0.871...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Ooh\\r\\nOoh\\r\\nOoh, oooh\\r\\n\\r\\nDon't get too t...</td>\n",
       "      <td>[(ooohDon't, ORG), (loveDon't, PERSON), (endDo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Rank                         Song Artist  Year  \\\n",
       "1044    41  Listen to what the man said  Wings  1975   \n",
       "1104     1             Silly love songs  Wings  1976   \n",
       "1170    67                    Let em in  Wings  1976   \n",
       "1321    18           With a little luck  Wings  1978   \n",
       "1456    52            Goodnight tonight  Wings  1979   \n",
       "\n",
       "                                                 Lyrics         Genre  \\\n",
       "1044  All right ,  okay ,  he-he-he Very good to see...          Rock   \n",
       "1104  You'd think that people would've had enough of...  Classic Rock   \n",
       "1170  Someone knockin' at the door Somebody ringin' ...          Rock   \n",
       "1321  With a little luck we can help it out We can m...           Pop   \n",
       "1456  Ooh Ooh Ooh ,  oooh  Don't get too tired for l...          Rock   \n",
       "\n",
       "                            Album  \\\n",
       "1044               Venus And Mars   \n",
       "1104  Wings At The Speed Of Sound   \n",
       "1170                    Let Em In   \n",
       "1321                 All The Best   \n",
       "1456            Goodnight Tonight   \n",
       "\n",
       "                                                   Refs  word_count  \\\n",
       "1044                                                 {}         177   \n",
       "1104                                                 {}         356   \n",
       "1170  {0, 512, 513, 5, 1033, 1034, 12, 525, 1041, 19...         161   \n",
       "1321                                                 {}         390   \n",
       "1456                                                 {}         157   \n",
       "\n",
       "                                                   vect  \\\n",
       "1044  [0.09184183925390244, -0.9644627571105957, -0....   \n",
       "1104  [0.9979954957962036, -0.9818665981292725, -0.7...   \n",
       "1170  [0.9771664142608643, -0.9817811250686646, -0.1...   \n",
       "1321  [0.1736101657152176, -0.973969578742981, -0.24...   \n",
       "1456  [0.8664616346359253, -0.9701489210128784, -0.5...   \n",
       "\n",
       "                                                   sims  \\\n",
       "1044  [0.919452421458788, 0.9557877725117744, 0.9023...   \n",
       "1104  [0.9473304240175289, 0.9037747111017586, 0.944...   \n",
       "1170  [0.9666354500279337, 0.9205098334261539, 0.968...   \n",
       "1321  [0.9556965141341748, 0.9533317280316723, 0.961...   \n",
       "1456  [0.8957604971886108, 0.9092488375300588, 0.871...   \n",
       "\n",
       "                                           filteredRefs  \\\n",
       "1044                                                 []   \n",
       "1104                                                 []   \n",
       "1170  [0, 513, 1034, 531, 1047, 543, 32, 38, 549, 10...   \n",
       "1321                                                 []   \n",
       "1456                                                 []   \n",
       "\n",
       "                                           Lyrics_print  \\\n",
       "1044  All right, okay, he-he-he\\r\\nVery good to see ...   \n",
       "1104  You'd think that people would've had enough of...   \n",
       "1170  Someone knockin' at the door\\r\\nSomebody ringi...   \n",
       "1321  With a little luck we can help it out\\r\\nWe ca...   \n",
       "1456  Ooh\\r\\nOoh\\r\\nOoh, oooh\\r\\n\\r\\nDon't get too t...   \n",
       "\n",
       "                                               Entities  \n",
       "1044          [(New Orleans, GPE), (blindWell, PERSON)]  \n",
       "1104  [(againI, PERSON), (againI, PERSON), (allHow, ...  \n",
       "1170  [(Suzy, PERSON), (JohnMartin Luther, PERSON), ...  \n",
       "1321  [(end(There, PERSON), (end(There, PERSON), (lu...  \n",
       "1456  [(ooohDon't, ORG), (loveDon't, PERSON), (endDo...  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.Artist == \"Wings\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "all_docs = np.concatenate((df.Lyrics.fillna(\"\"), df_events.Content.fillna(\"\")))\n",
    "\n",
    "documents = [TaggedDocument(doc.split(\" \"), [i]) for i, doc in enumerate(all_docs)]\n",
    "model = Doc2Vec(documents, vector_size=300, window=4, min_count=1, workers=4, epochs = 10, dbow_words = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics2events_sim = []\n",
    "for i in tqdm_notebook(range(len(df))):\n",
    "    sims = model.docvecs.most_similar(positive = [model.docvecs[i]], topn=100, clip_start=len(df))[1:]\n",
    "    sims = [x for x in sims if (x[0] - len(df)) in df.xs(i).Refs]\n",
    "    sims_refs = sorted(sims, key = lambda x : x[1], reverse=True)[:10]\n",
    "    lyrics2events_sim.append(sims_refs)\n",
    "df[\"Similar\"] = lyrics2events_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[df.Similar.apply(len) > 0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SimonRoquette\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\SimonRoquette\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\SimonRoquette\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\SimonRoquette\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\SimonRoquette\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\SimonRoquette\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from transformers import AlbertModel, AlbertTokenizer\n",
    "from tqdm import tqdm_notebook\n",
    "import torch\n",
    "\n",
    "tokenizer = AlbertTokenizer.from_pretrained('albert-large-v2')\n",
    "model = AlbertModel.from_pretrained('albert-large-v2')\n",
    "input_ids = torch.tensor(tokenizer.encode(\"Hello, my dog is cute\", add_special_tokens=True)).unsqueeze(0)  # Batch size 1\n",
    "outputs = model(input_ids)\n",
    "last_hidden_states = outputs[0]  # The last hidden-state is the first element of the output tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():  \n",
    "    dev = \"cuda:0\"\n",
    "    model.cuda()\n",
    "else:  \n",
    "    dev = \"cpu\"  \n",
    "device = torch.device(dev)  \n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"word_count\"] = df[\"Lyrics\"].apply(lambda x : len(x.split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics_tokenized = torch.Tensor(tokenizer.batch_encode_plus(df.Lyrics,\n",
    "                                                            max_length =512,\n",
    "                                                           pad_to_max_length=True,\n",
    "                                                           padding_side = \"right\",\n",
    "                                                           add_special_tokens=True)[\"input_ids\"]).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SimonRoquette\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f4ea3ae2c7a460b9d7a9fca7167d28b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=640.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lyrics_vectorized = []\n",
    "batch_size = 8\n",
    "with torch.no_grad():\n",
    "    for i in tqdm_notebook(range(0, len(df), batch_size)):\n",
    "        batch = lyrics_tokenized[i: min(i + batch_size, len(df))].to(device)\n",
    "        lyrics_vectorized.append(model(batch)[1].tolist())\n",
    "        del batch\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics_vectors = []\n",
    "for batch_lyrics in lyrics_vectorized:\n",
    "    for lyric in batch_lyrics:\n",
    "        lyrics_vectors.append(lyric)\n",
    "        \n",
    "df[\"vect\"] = lyrics_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_events[\"text_vect\"] = df_events.Summary.fillna(df_events.Content)\n",
    "df_events[\"word_count\"] = df_events[\"text_vect\"].apply(lambda x : len(x.split(\" \")))\n",
    "df_events[\"text_vect\"] = np.where(df_events[\"word_count\"] > 320, df_events.Content, df_events[\"text_vect\"])\n",
    "df_events[\"word_count\"] = df_events[\"text_vect\"].apply(lambda x : len(x.split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_tokenized = torch.Tensor(tokenizer.batch_encode_plus(df_events.text_vect,\n",
    "                                                            max_length =512,\n",
    "                                                           pad_to_max_length=True,\n",
    "                                                           padding_side = \"right\",\n",
    "                                                           add_special_tokens=True)[\"input_ids\"]).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SimonRoquette\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f16480aaedbf41a785fbfacae00bce71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=140.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "events_vectorized = []\n",
    "batch_size = 8\n",
    "with torch.no_grad():\n",
    "    for i in tqdm_notebook(range(0, len(df_events), batch_size)):\n",
    "        batch = events_tokenized[i: min(i + batch_size, len(df_events))].to(device)\n",
    "        events_vectorized.append(model(batch)[1].tolist())\n",
    "        del batch\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_vectors = []\n",
    "for batch_events in events_vectorized:\n",
    "    for event in batch_events:\n",
    "        events_vectors.append(event)\n",
    "        \n",
    "df_events[\"vect\"] = events_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Lyrics_print\"] = tmp_songs.Lyrics\n",
    "df.Lyrics = df.Lyrics_print.apply(lambda x : x.replace(\"\\r\\n\", \" \"))\n",
    "df.Lyrics = df.Lyrics.apply(lambda s : re.sub('([.,!?()])', r' \\1 ', s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Rank</th>\n",
       "      <th>Song</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Year</th>\n",
       "      <th>Lyrics</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Album</th>\n",
       "      <th>Youtube</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>wooly bully</td>\n",
       "      <td>sam the sham and the pharaohs</td>\n",
       "      <td>1965</td>\n",
       "      <td>Uno, dos\\r\\nOne, two, tres, quatro\\r\\nMatty to...</td>\n",
       "      <td>rock</td>\n",
       "      <td>wooly bully</td>\n",
       "      <td>https://www.youtube.com/watch?v=uE_MpQhgtQ8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>i cant help myself sugar pie honey bunch</td>\n",
       "      <td>four tops</td>\n",
       "      <td>1965</td>\n",
       "      <td>Uuh\\r\\nSugar pie, honey bunch\\r\\nYou know that...</td>\n",
       "      <td>r&amp;b soul</td>\n",
       "      <td>greatest hits in concert</td>\n",
       "      <td>https://www.youtube.com/watch?v=s3bksUSPB4c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>i cant get no satisfaction</td>\n",
       "      <td>the rolling stones</td>\n",
       "      <td>1965</td>\n",
       "      <td>I can't get no satisfaction\\r\\nI can't get no ...</td>\n",
       "      <td>rock</td>\n",
       "      <td>out of our heads</td>\n",
       "      <td>https://www.youtube.com/watch?v=nrIPxlFzDi0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>you were on my mind</td>\n",
       "      <td>we five</td>\n",
       "      <td>1965</td>\n",
       "      <td>When I woke up this morning\\r\\nYou were on my ...</td>\n",
       "      <td>folk</td>\n",
       "      <td>love me not tomorrow</td>\n",
       "      <td>https://www.youtube.com/watch?v=fPbXphLLUjg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>youve lost that lovin feelin</td>\n",
       "      <td>the righteous brothers</td>\n",
       "      <td>1965</td>\n",
       "      <td>You never close your eyes anymore when I kiss ...</td>\n",
       "      <td>r&amp;b soul</td>\n",
       "      <td>top gun</td>\n",
       "      <td>https://www.youtube.com/watch?v=uOnYY9Mw2Fg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Rank                                      Song  \\\n",
       "0             0     1                               wooly bully   \n",
       "1             1     2  i cant help myself sugar pie honey bunch   \n",
       "2             2     3                i cant get no satisfaction   \n",
       "3             3     4                       you were on my mind   \n",
       "4             4     5              youve lost that lovin feelin   \n",
       "\n",
       "                          Artist  Year  \\\n",
       "0  sam the sham and the pharaohs  1965   \n",
       "1                      four tops  1965   \n",
       "2             the rolling stones  1965   \n",
       "3                        we five  1965   \n",
       "4         the righteous brothers  1965   \n",
       "\n",
       "                                              Lyrics     Genre  \\\n",
       "0  Uno, dos\\r\\nOne, two, tres, quatro\\r\\nMatty to...      rock   \n",
       "1  Uuh\\r\\nSugar pie, honey bunch\\r\\nYou know that...  r&b soul   \n",
       "2  I can't get no satisfaction\\r\\nI can't get no ...      rock   \n",
       "3  When I woke up this morning\\r\\nYou were on my ...      folk   \n",
       "4  You never close your eyes anymore when I kiss ...  r&b soul   \n",
       "\n",
       "                      Album                                      Youtube  \n",
       "0               wooly bully  https://www.youtube.com/watch?v=uE_MpQhgtQ8  \n",
       "1  greatest hits in concert  https://www.youtube.com/watch?v=s3bksUSPB4c  \n",
       "2          out of our heads  https://www.youtube.com/watch?v=nrIPxlFzDi0  \n",
       "3      love me not tomorrow  https://www.youtube.com/watch?v=fPbXphLLUjg  \n",
       "4                   top gun  https://www.youtube.com/watch?v=uOnYY9Mw2Fg  "
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tmp_events = pd.read_csv(\"datasets/events/events_full.csv\", index_col=0, sep=\",\")\n",
    "# tmp_events.head()\n",
    "# tmp_songs = pd.read_csv(\"datasets/songs/billboard_full.csv\", index_col=0)\n",
    "# tmp_songs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics.pairwise import euclidean_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = cosine_similarity(df[\"vect\"].tolist(), df_events[\"vect\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2ec70ea2ec8>"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.filteredRefs.apply(len).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterRefs(row):\n",
    "    filteredRefs = []\n",
    "    for ref in row[\"Refs\"]:\n",
    "        if row[\"sims\"][ref] > 0.94:\n",
    "            filteredRefs.append(ref)\n",
    "    return filteredRefs\n",
    "\n",
    "df[\"filteredRefs\"] = df.apply(filterRefs, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SimonRoquette\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34f18ef3cfec48cc9efbca4a6d0a1f97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Add references to songs in events\n",
    "\"\"\"\n",
    "df_events[\"filteredRefs\"] = [[] for i in range(len(df_events))]\n",
    "for i_song, refs in tqdm_notebook(df[\"filteredRefs\"].iteritems()):\n",
    "    for i_event in refs:\n",
    "        df_events.iloc[i_event][\"filteredRefs\"].append(i_song)\n",
    "        \n",
    "df_events[\"filteredRefs\"] = df_events[\"filteredRefs\"].apply(set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[\"filteredRefs\"].apply(len).max())\n",
    "print(df[\"filteredRefs\"].apply(len).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_events.Entities.apply(lambda l : [x[0] for x in l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_events[\"Ents\"] = df_events.Entities.apply(lambda l : [x[0] for x in l])\n",
    "df_events[\"Ents_types\"] = df_events.Entities.apply(lambda l : [x[1] for x in l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Ents\"] = df.Entities.apply(lambda l : [x[0] for x in l])\n",
    "df[\"Ents_types\"] = df.Entities.apply(lambda l : [x[1] for x in l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_events.filteredRefs.apply(len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save to csv for Website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_events[\"num_refs\"] = df_events.filteredRefs.apply(len)\n",
    "df[\"num_refs\"] = df.filteredRefs.apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Year', 'Month', 'Day', 'Content', 'Wikipedia', 'Summary', 'Refs',\n",
       "       'vect', 'filteredRefs', 'num_refs', 'Entities', 'Entities_more'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_events.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Rank', 'Song', 'Artist', 'Year', 'Lyrics', 'Genre', 'Album', 'Refs',\n",
       "       'word_count', 'vect', 'sims', 'filteredRefs', 'Lyrics_print',\n",
       "       'Entities', 'Entities_more'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Youtube\"] = tmp_songs.Youtube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entities_embedding(row, songs = True):\n",
    "    col = \"Lyrics_print\" if songs else \"Summary\"\n",
    "    \n",
    "    color = \"#ffffff\" if songs else \"#f28e61\"\n",
    "    text_color = \"#ffffff\" if not songs else \"\"\n",
    "    \n",
    "    if len(row[\"Entities_more\"]) == 0:\n",
    "        return row[col]\n",
    "    \n",
    "    s = \"\"\n",
    "    original = row[col]\n",
    "    prev_end = 0\n",
    "    for ent, ent_type, start, end in row[\"Entities_more\"]:\n",
    "        s += original[prev_end : start]\n",
    "        embedded_entity = (\"<mark class=\\\"entity\\\" style=\\\"background: %s; padding: 0.05em 0.05em; margin: 0 0.15em;\"\n",
    "        \"line-height: 1; border-radius: 0.35em;\\\">%s\"\n",
    "        \"<span style=\\\"font-size: 0.65em; font-weight: bold;%s line-height: 1; border-radius: 0.35em; text-transform: uppercase;\"\n",
    "        \"vertical-align: middle; margin-left: 0.25rem; margin-bottom:0.25rem\\\">%s</span></mark>\"\"\") % (color, ent, text_color, ent_type)\n",
    "        s += embedded_entity\n",
    "        prev_end = end\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_events[\"Summary_embedded\"] = df_events.apply(entities_embedding, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_events.drop(columns = [\"vect\", \"Refs\", \"Entities\", \"word_count\", \"text_vect\"])\\\n",
    ".to_csv(\"datasets/events_refs_website.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Lyrics_print_embedded\"] = df.apply(entities_embedding, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns = [\"vect\", \"sims\", \"Refs\", \"word_count\", \"Entities\", \"Lyrics\"]).rename(columns = {\"Lyrics_display\": \"Lyrics\"})\\\n",
    ".to_csv(\"datasets/songs_refs_website.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.18190699491989"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Entities_more.apply(len).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Song</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Year</th>\n",
       "      <th>Lyrics</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Album</th>\n",
       "      <th>Refs</th>\n",
       "      <th>word_count</th>\n",
       "      <th>vect</th>\n",
       "      <th>sims</th>\n",
       "      <th>filteredRefs</th>\n",
       "      <th>Lyrics_print</th>\n",
       "      <th>Entities</th>\n",
       "      <th>Entities_more</th>\n",
       "      <th>num_refs</th>\n",
       "      <th>Youtube</th>\n",
       "      <th>Lyrics_print_embedded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1219</th>\n",
       "      <td>16</td>\n",
       "      <td>Whatcha gonna do</td>\n",
       "      <td>Pablo Cruise</td>\n",
       "      <td>1977</td>\n",
       "      <td>Whatcha gonna do When she says goodbye Whatcha...</td>\n",
       "      <td>Pop</td>\n",
       "      <td>A Place In The Sun</td>\n",
       "      <td>{}</td>\n",
       "      <td>270</td>\n",
       "      <td>[0.7500965595245361, -0.9582203030586243, -0.4...</td>\n",
       "      <td>[0.9548602001877042, 0.9568061277065438, 0.925...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Whatcha gonna do\\r\\nWhen she says goodbye\\r\\nW...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.youtube.com/watch?v=NPWqe7l6JK8</td>\n",
       "      <td>Whatcha gonna do\\r\\nWhen she says goodbye\\r\\nW...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Rank              Song        Artist  Year  \\\n",
       "1219    16  Whatcha gonna do  Pablo Cruise  1977   \n",
       "\n",
       "                                                 Lyrics Genre  \\\n",
       "1219  Whatcha gonna do When she says goodbye Whatcha...   Pop   \n",
       "\n",
       "                   Album Refs  word_count  \\\n",
       "1219  A Place In The Sun   {}         270   \n",
       "\n",
       "                                                   vect  \\\n",
       "1219  [0.7500965595245361, -0.9582203030586243, -0.4...   \n",
       "\n",
       "                                                   sims filteredRefs  \\\n",
       "1219  [0.9548602001877042, 0.9568061277065438, 0.925...           []   \n",
       "\n",
       "                                           Lyrics_print Entities  \\\n",
       "1219  Whatcha gonna do\\r\\nWhen she says goodbye\\r\\nW...       []   \n",
       "\n",
       "     Entities_more  num_refs                                      Youtube  \\\n",
       "1219            []         0  https://www.youtube.com/watch?v=NPWqe7l6JK8   \n",
       "\n",
       "                                  Lyrics_print_embedded  \n",
       "1219  Whatcha gonna do\\r\\nWhen she says goodbye\\r\\nW...  "
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.Song.str.contains(\"Whatcha gonna\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_events.drop(columns = [\"vect\", \"Refs\", \"Entities\", \"word_count\", \"text_vect\"])\\\n",
    ".to_csv(\"datasets/events_refs_website.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns = [\"vect\", \"sims\", \"Refs\", \"word_count\", \"Entities\", \"Lyrics\"]).rename(columns = {\"Lyrics_display\": \"Lyrics\"})\\\n",
    ".to_csv(\"datasets/songs_refs_website.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_events[[\"Year\", \"Month\", \"Day\", \"Content\", \"Wikipedia\", \"Summary\", \"Entities\", \"filteredRefs\", \"num_refs\"]]\\\n",
    ".to_json(\"events_refs_final.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_events[[\"Year\", \"Month\", \"Day\", \"Content\", \"Wikipedia\", \"Summary\", \"Entities\", \"filteredRefs\", \"num_refs\"]]\\\n",
    ".a\n",
    ".to_csv(\"events_refs_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.read_csv(\"events_refs_final.csv\", index_col = 0)\n",
    "tmp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_events.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"num_refs\"] = df[\"filteredRefs\"].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_events[\"num_refs\"] = df_events[\"filteredRefs\"].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"filteredRefs\"].apply(len) == 0].Year.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_events[\"filteredRefs\"].apply(len).max())\n",
    "print(df_events[\"filteredRefs\"].apply(len).mean())\n",
    "print(df_events[\"Refs\"].apply(len).max())\n",
    "print(df_events[\"Refs\"].apply(len).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[\"filteredRefs\"].apply(len).max())\n",
    "print(df[\"filteredRefs\"].apply(len).mean())\n",
    "print(df[\"Refs\"].apply(len).max())\n",
    "print(df[\"Refs\"].apply(len).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"events_vects.pickle\", \"rb\") as f:\n",
    "    tmp = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"events_vects.pickle\", \"wb\") as f:\n",
    "    pickle.dump(events_vectorized, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.Artist.str.contains(\"dire straits\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_vectorized = []\n",
    "batch_size = 8\n",
    "with torch.no_grad():\n",
    "    for i in tqdm_notebook(range(0, len(df_events), batch_size)):\n",
    "        batch = events_tokenized[i: min(i + batch_size, len(df_events))].to(device)\n",
    "        events_vectorized.append(model(batch))\n",
    "        del batch\n",
    "        \n",
    "events_vectorized = [x[1] for x in events_vectorized]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_vectors = []\n",
    "for batch_event in events_vectorized:\n",
    "    for event in batch_event:\n",
    "        events_vectors.append(event.tolist())\n",
    "        \n",
    "df_events[\"vect\"] = events_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_events.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_events.Refs.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"text_vect\"] = df.Summary.fillna(df_events.Content)\n",
    "# df[\"word_count\"] = df[\"Lyrics\"].apply(lambda x : len(x.split(\" \")))\n",
    "# df[\"text_vect\"] = np.where(df[\"word_count\"] > 400, df_events.Content, df_events[\"text_vect\"])\n",
    "# df[\"word_count\"] = df_events[\"text_vect\"].apply(lambda x : len(x.split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = [ for sent in df_events[\"text_vect\"]]\n",
    "x = torch.tensor(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(model.docvecs.vectors_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(model.docvecs.vectors_docs).to_csv(\"vec.tsv\", index = False, sep = \"\\t\", header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data.tsv\", sep = \"\\t\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
